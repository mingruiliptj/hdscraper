{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dda63ad",
   "metadata": {},
   "source": [
    "\n",
    "# Human Image Scraper for Machine Learning Datasets\n",
    "\n",
    "This notebook allows you to scrape images of humans with various attributes to create training datasets.\n",
    "It has built-in face detection to center crops on faces, and produces 1024x1024 pixel images suitable for machine learning.\n",
    "All images are saved directly to your Google Drive in the structure: `/content/drive/MyDrive/Loras/[project_name]/dataset/`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d3a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check if running in Colab\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Running in Google Colab: {IN_COLAB}\")\n",
    "\n",
    "# Mount Google Drive\n",
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"Google Drive mounted at /content/drive\")\n",
    "\n",
    "# Install required packages\n",
    "!pip install -q requests\n",
    "!pip install -q Pillow\n",
    "!pip install -q google-api-python-client\n",
    "!pip install -q duckduckgo-search\n",
    "!pip install -q tqdm\n",
    "\n",
    "# Install face_recognition (more complex in Colab)\n",
    "if IN_COLAB:\n",
    "    !apt-get -qq install -y libsm6 libxext6 libxrender-dev libglib2.0-0\n",
    "    !pip install -q dlib\n",
    "    !pip install -q face_recognition\n",
    "else:\n",
    "    !pip install -q face_recognition\n",
    "\n",
    "!pip install -q numpy\n",
    "\n",
    "# Display versions for debugging\n",
    "!pip list | grep -E \"requests|Pillow|google|duckduckgo|tqdm|face|numpy|dlib\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2661c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from googleapiclient.discovery import build\n",
    "from duckduckgo_search import DDGS\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from google.colab import files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5be2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageScraper:\n",
    "    def __init__(self, api_key=None):\n",
    "        self.google_api_key = api_key\n",
    "        self.target_size = (1024, 1024)\n",
    "        self.setup_logging()\n",
    "\n",
    "    def setup_logging(self):\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
    "        )\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "\n",
    "    def create_save_directory(self, project_name):\n",
    "        # Create directory structure: Loras/project_name/dataset\n",
    "        save_path = os.path.join('/content/drive/MyDrive/Loras', project_name, 'dataset')\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        self.logger.info(f\"Saving images to Google Drive path: {save_path}\")\n",
    "        return save_path\n",
    "\n",
    "    def crop_center(self, image):\n",
    "        width, height = image.size\n",
    "        \n",
    "        # Calculate dimensions for center crop\n",
    "        if width > height:\n",
    "            left = (width - height) // 2\n",
    "            top = 0\n",
    "            right = left + height\n",
    "            bottom = height\n",
    "        else:\n",
    "            top = (height - width) // 2\n",
    "            left = 0\n",
    "            bottom = top + width\n",
    "            right = width\n",
    "            \n",
    "        # Get the center crop\n",
    "        cropped = image.crop((left, top, right, bottom))\n",
    "        \n",
    "        # If the cropped image is still larger than 1024x1024, take the center 1024x1024\n",
    "        if cropped.size[0] > 1024:\n",
    "            size = cropped.size[0]\n",
    "            margin = (size - 1024) // 2\n",
    "            cropped = cropped.crop((margin, margin, margin + 1024, margin + 1024))\n",
    "            \n",
    "        return cropped\n",
    "\n",
    "    def resize_keeping_aspect_ratio(self, image, target_size):\n",
    "        \"\"\"Resize image to target size while maintaining aspect ratio\"\"\"\n",
    "        width, height = image.size\n",
    "        aspect_ratio = width / height\n",
    "        \n",
    "        if aspect_ratio > 1:  # width > height\n",
    "            new_width = target_size[0]\n",
    "            new_height = int(new_width / aspect_ratio)\n",
    "        else:  # height > width\n",
    "            new_height = target_size[1]\n",
    "            new_width = int(new_height * aspect_ratio)\n",
    "            \n",
    "        return image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "    def crop_around_face(self, image):\n",
    "        \"\"\"Crop image to 1024x1024 keeping faces centered\"\"\"\n",
    "        # Convert PIL Image to numpy array for face_recognition\n",
    "        img_array = np.array(image)\n",
    "        \n",
    "        # Detect faces\n",
    "        face_locations = face_recognition.face_locations(img_array)\n",
    "        \n",
    "        if not face_locations:\n",
    "            # If no faces detected, fall back to center crop\n",
    "            self.logger.debug(\"No faces detected, using center crop\")\n",
    "            return self.crop_center(image)\n",
    "            \n",
    "        # Calculate the center point of all faces\n",
    "        centers = []\n",
    "        for top, right, bottom, left in face_locations:\n",
    "            center_x = (left + right) // 2\n",
    "            center_y = (top + bottom) // 2\n",
    "            centers.append((center_x, center_y))\n",
    "            \n",
    "        # Use the average center point of all faces\n",
    "        center_x = int(sum(x for x, _ in centers) / len(centers))\n",
    "        center_y = int(sum(y for _, y in centers) / len(centers))\n",
    "        \n",
    "        # Calculate crop box\n",
    "        width, height = image.size\n",
    "        crop_size = 1024\n",
    "        \n",
    "        # Ensure the crop box stays within image boundaries\n",
    "        left = max(0, min(center_x - crop_size // 2, width - crop_size))\n",
    "        top = max(0, min(center_y - crop_size // 2, height - crop_size))\n",
    "        right = left + crop_size\n",
    "        bottom = top + crop_size\n",
    "        \n",
    "        return image.crop((left, top, right, bottom))\n",
    "\n",
    "    def process_image(self, image_url, save_path, index):\n",
    "        try:\n",
    "            response = requests.get(image_url, timeout=10)\n",
    "            if response.status_code != 200:\n",
    "                return False\n",
    "\n",
    "            # Open image and convert to RGB\n",
    "            image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "            width, height = image.size\n",
    "\n",
    "            # Skip if image is too small\n",
    "            if width < 1024 or height < 1024:\n",
    "                self.logger.debug(f\"Skipping small image {width}x{height}: {image_url}\")\n",
    "                return False\n",
    "\n",
    "            # Resize image while maintaining aspect ratio\n",
    "            # Make sure the smaller dimension is at least 1024px\n",
    "            if width < height:\n",
    "                new_width = 1024\n",
    "                new_height = int(height * (new_width / width))\n",
    "            else:\n",
    "                new_height = 1024\n",
    "                new_width = int(width * (new_height / height))\n",
    "                \n",
    "            image = self.resize_keeping_aspect_ratio(image, (new_width, new_height))\n",
    "\n",
    "            # Crop around face to exactly 1024x1024\n",
    "            cropped_image = self.crop_around_face(image)\n",
    "            \n",
    "            # Verify final size\n",
    "            if cropped_image.size != (1024, 1024):\n",
    "                self.logger.error(f\"Unexpected crop size {cropped_image.size}\")\n",
    "                return False\n",
    "\n",
    "            # Generate unique filename based on image content\n",
    "            image_hash = hashlib.md5(response.content).hexdigest()[:10]\n",
    "            filename = f\"image_{index}_{image_hash}.jpg\"\n",
    "            save_path = os.path.join(save_path, filename)\n",
    "            \n",
    "            # Save the image with high quality\n",
    "            cropped_image.save(save_path, \"JPEG\", quality=95)\n",
    "            self.logger.info(f\"Saved image {filename} (original size: {width}x{height})\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error processing image {image_url}: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    def search_duckduckgo(self, keyword, max_results):\n",
    "        image_urls = []\n",
    "        try:\n",
    "            with DDGS() as ddgs:\n",
    "                results = ddgs.images(\n",
    "                    keyword,\n",
    "                    max_results=max_results * 3  # Get more results since we're being more selective\n",
    "                )\n",
    "                for r in results:\n",
    "                    if r['image']:\n",
    "                        image_urls.append(r['image'])\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error searching DuckDuckGo: {str(e)}\")\n",
    "        return image_urls\n",
    "\n",
    "    def scrape_images(self, main_keyword, sub_keywords, save_folder, num_images_per_keyword):\n",
    "        \"\"\"\n",
    "        Main function to scrape and process images\n",
    "        \"\"\"\n",
    "        save_path = self.create_save_directory(save_folder)\n",
    "        self.logger.info(f\"Saving images to: {save_path}\")\n",
    "        self.logger.info(\"Note: Only processing images with minimum 1024x1024 pixels\")\n",
    "        \n",
    "        total_successful_downloads = 0\n",
    "        # Split sub-keywords and process each one\n",
    "        sub_keyword_list = [sk.strip() for sk in sub_keywords.split(',')]\n",
    "        self.logger.info(f\"Processing {len(sub_keyword_list)} sub-keywords: {sub_keyword_list}\")\n",
    "        \n",
    "        for sub_keyword in sub_keyword_list:\n",
    "            if not sub_keyword:\n",
    "                continue\n",
    "                \n",
    "            search_query = f\"{main_keyword} {sub_keyword}\"\n",
    "            self.logger.info(f\"Searching for: {search_query}\")\n",
    "            \n",
    "            # Collect image URLs from different sources\n",
    "            image_urls = self.search_duckduckgo(search_query, num_images_per_keyword * 3)\n",
    "            self.logger.info(f\"Found {len(image_urls)} potential images for '{search_query}'\")\n",
    "\n",
    "            # Process images with progress bar\n",
    "            successful_downloads = 0\n",
    "            with tqdm(total=num_images_per_keyword, desc=f\"Processing '{sub_keyword}'\") as pbar:\n",
    "                with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "                    for i, url in enumerate(image_urls):\n",
    "                        if successful_downloads >= num_images_per_keyword:\n",
    "                            break\n",
    "                            \n",
    "                        if self.process_image(url, save_path, f\"{sub_keyword}_{i}\"):\n",
    "                            successful_downloads += 1\n",
    "                            total_successful_downloads += 1\n",
    "                            pbar.update(1)\n",
    "\n",
    "            self.logger.info(f\"Downloaded {successful_downloads} images for '{search_query}'\")\n",
    "        \n",
    "        self.logger.info(f\"Total successfully downloaded images: {total_successful_downloads}\")\n",
    "        return total_successful_downloads\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa96c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create an instance of the scraper\n",
    "scraper = ImageScraper()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cf1c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set parameters for image scraping\n",
    "main_keyword = input(\"Enter main keyword (e.g., 'human'): \")\n",
    "sub_keywords = input(\"Enter sub-keywords separated by commas (e.g., 'profile, face, portrait'): \")\n",
    "project_name = input(\"Enter project name (folder will be created in Google Drive): \")\n",
    "num_images_per_keyword = int(input(\"Enter number of images to download per sub-keyword: \"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a22b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run the scraper\n",
    "total_images = scraper.scrape_images(main_keyword, sub_keywords, project_name, num_images_per_keyword)\n",
    "print(f\"Total images downloaded: {total_images}\")\n",
    "print(f\"Images saved to: /content/drive/MyDrive/Loras/{project_name}/dataset/\")\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
